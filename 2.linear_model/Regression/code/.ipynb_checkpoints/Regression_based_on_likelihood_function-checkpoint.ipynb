{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于$\\varepsilon$假设"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T12:04:42.276520Z",
     "start_time": "2019-10-28T12:04:42.270525Z"
    }
   },
   "source": [
    "对于线性模型，我们常常使用Guass-Markon假设，即：\n",
    "1. $E(\\varepsilon) = 0$\n",
    "2. $cov(\\varepsilon) = \\sigma^2 I_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T12:12:09.781523Z",
     "start_time": "2019-10-28T12:12:09.772525Z"
    }
   },
   "source": [
    "但是，实际上我们同方差的假设经常是不满足的，完整来说，对$\\varepsilon$的假设应该有三种：\n",
    "1. 同方差，且各个随机误差变量不相关：$cov(\\varepsilon) = \\sigma^2 I_n$\n",
    "2. 异常差，但各个随机误差变量不相关，$cov(\\varepsilon) = diag(\\sigma_1^2, \\sigma_2^2, \\cdots, \\sigma_n^2)$\n",
    "3. 异方差，且各个随机误差变量是相关的，\n",
    "$$\n",
    "cov(\\varepsilon) =\n",
    "\\begin{pmatrix}\n",
    "    \\sigma_{11}^2 & cov(\\varepsilon_1, \\varepsilon_2) & \\cdots & cov(\\varepsilon_1, \\varepsilon_n)\\\\\n",
    "    cov(\\varepsilon_2, \\varepsilon_1) & \\sigma_{22}^2 & \\cdots & cov(\\varepsilon_2, \\varepsilon_n)\\\\\n",
    "    \\vdots & \\vdots &  & \\vdots\\\\\n",
    "    cov(\\varepsilon_n, \\varepsilon_1) & cov(\\varepsilon_n, \\varepsilon_2) & \\cdots & \\sigma_{nn}^2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "此时，记$cov(\\varepsilon) = \\Sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于似然函数的估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T13:03:44.688123Z",
     "start_time": "2019-10-28T13:03:44.681127Z"
    }
   },
   "source": [
    "之前是从损失函数的角度进行参数的估计，但是实际上每个损失函数都应该对应着一个分布，并使得分布的似然函数达到最大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T12:28:12.196941Z",
     "start_time": "2019-10-28T12:28:12.188944Z"
    }
   },
   "source": [
    "我们知道在X给定的情况下，似然函数$L(\\theta;Y,X) = P_{\\theta}(Y_1 = y_1, Y_2 = y_2, \\cdots, Y_n = y_n)$。假设$Y_1, Y_2, \\cdots, Y_n$是独立的，有$L(\\theta;Y,X) = \\prod_{i=1}^nP(Y = y_i)$。当是离散情况的时候，可以进一步化为：$L(\\theta;Y,X) = \\prod_{i=1}^nP_i(\\theta)$。当是连续情况的时候，则可以化为：$L(\\theta;Y,X) = \\prod_{i=1}^n f(y_i;\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于假设1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T12:37:56.985519Z",
     "start_time": "2019-10-28T12:37:56.975505Z"
    }
   },
   "source": [
    "如果满足假设1，$cov(\\varepsilon) = \\sigma I_n$， 并加上一个正态性的假设，即有$\\varepsilon_i \\sim N(0, \\sigma^2)$，那么，$y_i = x_i\\beta + \\varepsilon_i \\sim N(x_i\\beta, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T12:48:34.839352Z",
     "start_time": "2019-10-28T12:48:34.830358Z"
    }
   },
   "source": [
    "那么有似然函数\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        L(\\beta, \\sigma^2, Y, X) & = \\prod_{i=1}^n f(y_i)\\\\\n",
    "        & = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{- \\frac{(y_i - x_i\\beta)^2}{2\\sigma^2}}\\\\\n",
    "        & = (\\frac{1}{\\sqrt{2\\pi}\\sigma})^n e^{- \\frac{1}{2 \\sigma^2} \\displaystyle \\sum_{i=1}^n(y_i - x_i\\beta)^2}\n",
    "    \\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T14:00:55.911688Z",
     "start_time": "2019-10-28T14:00:55.904691Z"
    }
   },
   "source": [
    "可以看到，似然函数中含有的$\\sum_{i=1}^n(y_i - x_i\\beta)^2$部分正是我们之前讨论的二次损失形式，而有的时候也把这一部分称为核。那么我们便再次清晰地认识到，基于假设1时，确实是应该采用我们之前所使用的二次损失形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T12:53:23.546765Z",
     "start_time": "2019-10-28T12:53:23.540748Z"
    }
   },
   "source": [
    "通常为了简便计算，我们都会将似然函数对数化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T12:56:48.463197Z",
     "start_time": "2019-10-28T12:56:48.452201Z"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        lnL(\\beta, \\sigma^2, Y, X) & = -nln(\\sqrt{2\\pi}\\sigma)- \\frac{1}{2 \\sigma^2} \\sum_{i=1}^n(y_i - x_i\\beta)^2\n",
    "    \\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T13:05:20.864063Z",
     "start_time": "2019-10-28T13:05:20.857087Z"
    }
   },
   "source": [
    "记$G(\\beta, \\sigma^2) = nln(\\sqrt{2\\pi}\\sigma) + \\frac{1}{2 \\sigma^2} \\sum_{i=1}^n(y_i - x_i\\beta)^2$，令似然函数最大化，即是求$min \\hspace{1mm}G(\\beta, \\sigma^2)$\n",
    "\n",
    "对$G(\\beta, \\sigma^2)$求关于$\\beta$的偏导有\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\frac {\\partial G(\\beta, \\sigma^2)}{\\partial \\beta} \n",
    "        &= 0 + \\frac{1}{2 \\sigma^2}2 \\displaystyle \\sum_{i=1}^n (y_i - x_i\\beta)x_i\\\\\n",
    "        & = \\frac{1}{2 \\sigma^2} \\displaystyle \\sum_{i=1}^n 2(x_iy_i - x_i^2\\beta) = 0\n",
    "    \\end{split}\n",
    "    \\\\\n",
    "    => \\displaystyle \\sum_{i=1}^n (x_iy_i - x_i^2\\beta) = 0 => \\displaystyle \\sum_{i=1}^n x_iy_i = \\displaystyle \\sum_{i=1}^n x_i^2\\beta\\\\\n",
    "    => X^TY = X^TX\\beta => \\hat \\beta = (X^TX)^{-1}X^TY\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T13:37:02.912596Z",
     "start_time": "2019-10-28T13:37:02.900603Z"
    }
   },
   "source": [
    "对对$G(\\beta, \\sigma^2)$求关于$\\sigma$的偏导有\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\frac {\\partial G(\\beta, \\sigma^2)}{\\partial \\sigma} \n",
    "        &= n\\frac{1}{\\sqrt{2\\pi}\\sigma}\\sqrt{2\\pi} - \\frac{2}{2\\sigma^3}\\sum_{i=1}^n(y_i - x_i\\beta)^2 \\\\\n",
    "        & = \\frac{n}{\\sigma} + \\frac{1}{\\sigma^3}\\sum_{i=1}^n(y_i - x_i\\beta)^2  = 0\n",
    "    \\end{split}\n",
    "    \\\\\n",
    "    => \\frac{1}{\\sigma^3}\\sum_{i=1}^n(y_i - x_i\\beta)^2 = \\frac{n}{\\sigma}\n",
    "    => \\hat \\sigma^2 = \\frac{\\displaystyle \\sum_{i=1}^n(y_i - x_i\\beta)^2}{n}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "值得注意的是，这里的$x_i\\beta$中的$\\beta$并不是估计量，这整个代表的是真实的拟合值，所以自由度有所不同（和$\\hat \\sigma^2 = \\frac{SSE}{n-p}$略显不同）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T13:47:54.084635Z",
     "start_time": "2019-10-28T13:47:54.077640Z"
    }
   },
   "source": [
    "通过似然函数，一次将搞定了参数$\\beta$和$\\sigma$的估计，而基于损失函数的估计只是估计出了$\\beta$，而$\\sigma$是另外造一套理论估计的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于假设2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果满足假设2，$cov(\\varepsilon) = cov(\\varepsilon) = diag(\\sigma_1^2, \\sigma_2^2, \\cdots, \\sigma_n^2)$， 并加上一个正态性的假设，即有$\\varepsilon_i \\sim N(0, \\sigma^2_{ii})$，那么，$y_i = x_i\\beta + \\varepsilon_i \\sim N(x_i\\beta, \\sigma^2_{ii})$，此时实际上要估计n+1个参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T13:53:37.982492Z",
     "start_time": "2019-10-28T13:53:37.969503Z"
    }
   },
   "source": [
    "那么有似然函数\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        L(\\beta, \\sigma^2, Y, X) & = \\prod_{i=1}^n f(y_i)\\\\\n",
    "        & = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma_{ii}} e^{- \\frac{(y_i - x_i\\beta)^2}{2\\sigma^2_{ii}}}\\\\\n",
    "        & = (\\frac{1}{\\sqrt{2\\pi}})^n \\prod_{i=1}^n(\\frac{1}{\\sigma_{ii}}) e^{- \\frac{1}{2} \\displaystyle \\sum_{i=1}^n(\\frac {y_i - x_i\\beta}{\\sigma_{ii}})^2}\n",
    "    \\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以发现基于假设2下，似然函数的核发生了变化。因此，根据之前的经验，基于假设2，所采用的损失函数也应该发生变化。此时采用的损失函数应该是标准化的二次损失$\\displaystyle \\sum_{i=1}^n(\\frac {y_i - x_i\\beta}{\\sigma_{ii}})^2$，我们也把这称为加权最小二乘估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将似然函数对数化：\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        lnL(\\beta, \\sigma^2, Y, X) & = -nln(\\sqrt{2\\pi})- \\sum_{i=1}^nln\\sigma_{ii} - \\frac{1}{2} \\displaystyle \\sum_{i=1}^n(\\frac {y_i - x_i\\beta}{\\sigma_{ii}})^2\n",
    "    \\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记$G(\\beta, \\sigma_{ii}^2) = nln(\\sqrt{2\\pi}) + \\sum_{i=1}^nln\\sigma_{ii} + \\frac{1}{2} \\displaystyle \\sum_{i=1}^n(\\frac {y_i - x_i\\beta}{\\sigma_{ii}})^2$，令似然函数最大化，即是求$min \\hspace{1mm}G(\\beta, \\sigma_{ii}^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对$G(\\beta, \\sigma_{ii}^2)$求关于$\\beta$的偏导有\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\frac {\\partial G(\\beta, \\sigma_{ii}^2)}{\\partial \\sigma_{ii}} \n",
    "        &= 0 + 0 - \\frac{1}{2}2 \\displaystyle \\sum_{i=1}^n (\\frac {y_i - x_i\\beta}{\\sigma_{ii}})\\frac{x_i}{\\sigma_{ii}}\\\\\n",
    "        & = - \\displaystyle \\sum_{i=1}^n (\\frac {x_iy_i - x_i^2\\beta}{\\sigma_{ii}^2}) = 0\n",
    "    \\end{split}\n",
    "    \\\\\n",
    "    => \\displaystyle \\sum_{i=1}^n (\\frac {x_iy_i}{\\sigma_{ii}^2}) = \\displaystyle \\sum_{i=1}^n (\\frac {x_i^2\\beta}{\\sigma_{ii}^2}) \\\\\n",
    "    => X_c^TY_c = X_c^TX_c\\beta => \\hat \\beta = (X_c^TX_c)^{-1}X_c^TY_c\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T00:37:55.945389Z",
     "start_time": "2019-10-29T00:37:55.937390Z"
    }
   },
   "source": [
    "记$X_c = (\\frac{x_1}{\\sigma_{11}}, \\frac{x_2}{\\sigma_{22}}, \\cdots, \\frac{x_n}{\\sigma_{nn}})^T, Y_c = (\\frac{y_1}{\\sigma_{11}}, \\frac{y_2}{\\sigma_{22}}, \\cdots, \\frac{y_n}{\\sigma_{nn}})^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T00:43:30.763832Z",
     "start_time": "2019-10-29T00:43:30.749840Z"
    }
   },
   "source": [
    "对$G(\\beta, \\sigma_{ii}^2)$求关于$\\sigma_{ii}$的偏导有，以$\\sigma_{11}$为例\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\frac {\\partial G(\\beta, \\sigma_{ii}^2)}{\\partial \\sigma_{11}} \n",
    "        &= 0 + \\frac{1}{\\sigma_{11}} - \\frac{1}{2}2\\frac{(y_1 - x_1\\beta)^2}{\\sigma_{11}^3} \\\\\n",
    "        & = \\frac{1}{\\sigma_{11}} - \\frac{(y_1 - x_1\\beta)^2}{\\sigma_{11}^3}  = 0\n",
    "    \\end{split}\n",
    "    \\\\\n",
    "    => \\frac{1}{\\sigma_{11}} = \\frac{(y_1 - x_1\\beta)^2}{\\sigma_{11}^3}\n",
    "    => \\hat \\sigma_{11}^2 = (y_1 - x_1\\beta)^2\n",
    "\\end{equation}\n",
    "\n",
    "类似地，也就有$\\hat \\sigma_{ii}^2 = (y_i - x_i\\beta)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于假设3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果满足假设3，$cov(\\varepsilon) = \\Sigma$， 并加上一个正态性的假设，即有$\\varepsilon$满足多维正态分布，$\\varepsilon \\sim N_n(0, \\sigma^2_{ii})$，那么，$Y = X\\beta + \\varepsilon \\sim N_n(X\\beta, \\Sigma)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T14:24:07.899094Z",
     "start_time": "2019-10-28T14:24:07.890103Z"
    }
   },
   "source": [
    "那么有似然函数\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        L(\\beta, \\Sigma Y, X) & =P(Y_1 = y_1, Y_2 = y_2, \\cdots, Y_n = y_n) = P(Y=y)\\\\\n",
    "    & = \\frac{1}{(\\sqrt{2\\pi})^n|\\Sigma|^{\\frac{1}{2}}}e ^{- \\frac{1}{2}(Y - X\\beta)^T \\sum^{-1} (Y - X\\beta)}\n",
    "    \\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T11:16:12.511800Z",
     "start_time": "2019-10-29T11:16:12.503802Z"
    }
   },
   "source": [
    "其中，$|\\Sigma|$是$\\Sigma$的行列式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以发现基于假设3下，似然函数的核同样也发生了变化。那么，基于这种假设，此时采用的损失函数应该是$(y - x\\beta)^T \\Sigma^{-1} (y - x\\beta)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将似然函数对数化：\n",
    "$$\n",
    "lnL(\\beta, \\Sigma, Y, X) = -nln(\\sqrt{2\\pi})- \\frac{1}{2}ln|\\Sigma| - \\frac{1}{2} (Y - X\\beta)^T (\\Sigma)^{-1} (Y - X\\beta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记$G(\\beta, \\Sigma) = nln(\\sqrt{2\\pi}) + \\frac{1}{2}ln|\\Sigma| + \\frac{1}{2} (Y - X\\beta)^T \\Sigma^{-1} (Y - X\\beta)$，令似然函数最大化，即是求$min \\hspace{1mm}G(\\beta, \\Sigma)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对$G(\\beta, \\Sigma)$求关于$\\beta$的偏导有\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\frac {\\partial G(\\beta, \\Sigma)}{\\partial \\beta} \n",
    "        &= 0 + 0 - \\frac{1}{2}2 X^T \\Sigma^{-1} (Y - X\\beta)\\\\\n",
    "        & = X^T \\Sigma^{-1}(X\\beta - Y) = 0\n",
    "    \\end{split}\n",
    "    \\\\\n",
    "    => X^T \\Sigma^{-1}X\\beta = X^T \\Sigma^{-1}Y \\\\\n",
    "    => \\hat \\beta = (X^T \\Sigma^{-1} X)^{-1}X^T \\Sigma^{-1} Y\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T11:17:52.136225Z",
     "start_time": "2019-10-29T11:17:52.122233Z"
    }
   },
   "source": [
    "对$G(\\beta, \\sum)$求关于$\\sum$的偏导有\n",
    "\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "         \\mathrm{d}G & = |\\Sigma|^{-1}d|\\Sigma| + \\frac{1}{2}(Y - X\\beta)^T\\Sigma^{-1}d\\Sigma\\Sigma^{-1}(Y-X\\beta)\\\\\n",
    "         & = \\frac{1}{2}tr(\\Sigma^{-1}d\\Sigma) + tr(\\frac{1}{2}(Y - X\\beta)^T\\Sigma^{-1}d\\Sigma\\Sigma^{-1}(Y-X\\beta))\\\\\n",
    "         & = \\frac{1}{2}tr(\\Sigma^{-1}d\\Sigma) + tr(\\frac{1}{2}\\Sigma^{-1}(Y-X\\beta)(Y - X\\beta)^T\\Sigma^{-1}d\\Sigma)\\\\\n",
    "         & = \\frac{1}{2}tr((\\Sigma^{-1} - \\Sigma^{-1}(Y-X\\beta)(Y - X\\beta)^T\\Sigma^{-1})d\\Sigma) \n",
    "    \\end{split}\n",
    "    \\\\\n",
    "    => \\frac{\\partial G}{\\partial \\Sigma} = (\\Sigma^{-1} - \\Sigma^{-1}(Y-X\\beta)(Y - X\\beta)^T\\Sigma^{-1})^T = 0\\\\\n",
    "    => \\Sigma^{-1}(Y-X\\beta)^T(Y - X\\beta)\\Sigma^{-1} = \\Sigma^{-1} \\\\\n",
    "    => \\hat \\Sigma = (Y-X\\beta)^T(Y - X\\beta)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 估计的优良性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T12:46:35.605363Z",
     "start_time": "2019-10-29T12:46:35.599365Z"
    }
   },
   "source": [
    "在基于损失函数的估计中，我们讨论了估计的优良性，那么当换了假设和损失函数后，我们的估计是否还是具有优良的性质呢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于假设3中，有\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        L_3(\\beta) & = (Y - X\\beta)^T \\Sigma^{-1} (Y - X\\beta) \\\\\n",
    "        & = (Y - X\\beta)^T \\Sigma^{-\\frac{1}{2}}\\Sigma^{-\\frac{1}{2}} (Y - X\\beta)\\\\\n",
    "        & = (\\Sigma^{-\\frac{1}{2}}Y - \\Sigma^{-\\frac{1}{2}}X\\beta)^T(\\Sigma^{-\\frac{1}{2}}Y - \\Sigma^{-\\frac{1}{2}}X\\beta)\\\\\n",
    "        & = (Y^* - X^* \\beta)^T(Y^* - X^* \\beta)\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "其中，记$\\Sigma^{-\\frac{1}{2}}Y - \\Sigma^{-\\frac{1}{2}}X\\beta$为$Y^* - X^* \\beta$，由于$L_1(\\beta) = (Y-X\\beta)^T(Y - X\\beta)$具有优良的性质，那么$L_3(\\beta) = (Y^* - X^* \\beta)^T(Y^* - X^* \\beta)$的估计也应该具有优良的性质"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
