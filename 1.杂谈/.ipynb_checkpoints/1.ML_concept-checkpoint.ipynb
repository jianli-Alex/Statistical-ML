{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习 vs 统计学习 vs 数据挖掘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:28:40.516560Z",
     "start_time": "2020-03-22T10:28:40.512559Z"
    }
   },
   "source": [
    "**1.1 机器学习：**直白地说就是，希望总从数据中总结出一些规律和模式，用于未来数据的预测\n",
    "- 形象化的定义（Mitchell）：若计算机程序利用经验E在任务T得到性能P的改善，就说该程序对E进行了学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T10:55:11.709195Z",
     "start_time": "2020-03-22T10:55:11.703655Z"
    }
   },
   "source": [
    "**1.2 统计学习：**基于计算机构建概率统计模型，并用于对数据的预测和分析\n",
    "- 统计学习是机器学习的主体部分，也称\"统计机器学习\"\n",
    "- 研究对象：以数据为对象，以数据驱动的方式\n",
    "    - 假设同类数据具有统计规律性\n",
    "    - 假设输入`X`和输出`Y`满足联合分布P(X, Y)\n",
    "    - 假设样本空间服从某个未知分布`D`，每个样本$iid$ 分布`D`(西瓜书)\n",
    "- 目的：在假设空间中获得一个好的模型，用于预测和分析\n",
    "- 中心：方法\n",
    "    - 监督学习：有标记`Y`和输入对应\n",
    "        - 预测值为连续值：回归\n",
    "            - 线性回归\n",
    "        - 预测值为离散值：分类\n",
    "            - logistic回归、SVM、朴素贝叶斯\n",
    "    - 无监督学习：没有标记`Y`，从输入找模式和规律\n",
    "    - 半监督学习：有一部分输入有对应的标记`Y`，有一部分没有\n",
    "        - 可能由于输入的采集较为容易，输出的采集较为困难\n",
    "    - 强化学习：某些行为给予反馈（正负）\n",
    "- 三要素：\n",
    "    - 模型\n",
    "        - [假设空间](#假设空间-vs-模型)：所有可能模型的集合\n",
    "        - 版本空间：与训练集一致的假设集合\n",
    "    - 策略：确定模型选择的准则\n",
    "    - 算法：求解最优模型的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T11:18:42.739494Z",
     "start_time": "2020-03-22T11:18:42.736514Z"
    }
   },
   "source": [
    "**1.3 数据挖掘：**从海量数据中学习知识\n",
    "- 数据库技术：为数据挖掘提供管理技术\n",
    "- 机器学习：为数据挖掘提供数据分析技术\n",
    "- 统计学的研究成果--> 机器学习 --> 有效的学习算法 --> 为数据挖掘分析服务 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据集：所有记录的集合\n",
    "- 样本/实例/属性/输入(sample/instance/attribute)：每一条记录，记为$x_i$\n",
    "- 标记(label)：输出，记为$y_i$\n",
    "- 特征(feature)：建模时的每个参数，记为$x_i^{(j)}$\n",
    "- 样例(example)：拥有标记信息的实例\n",
    "- 输入空间/样本空间/属性空间：输入所有可能的集合\n",
    "- 输出空间：输出所有可能的集合\n",
    "- 特征空间：所有特征组成的集合\n",
    "    - 输入空间和特征空间可能相同也可能不同\n",
    "    - 例如$y = ax^2 + bx$，$x$是输入，$x^2$和$x$是特征\n",
    "- 特征数：一个样本的特征数为维度\n",
    "    - 当维度大于样本数时，称为“维数灾难”\n",
    "- 特征向量：由一行特征组成的向量，模型的实际输入，记为$(x_i^{(1)}, x_i^{(2)}, ..., x_i^{(j)}, ...)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ml_concepts](./img/ml_concepts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算机程序学习经验数据生成算法模型的过程中，每一条记录称为一个“训练样本”，同时在训练好模型后，我们希望使用新的样本来测试模型的效果，则每一个新的样本称为一个“测试样本”。定义：\n",
    "- 所有训练样本的集合为：训练集（trainning set），[特殊]，记为$(x_1, x_2, ..., x_N)$\n",
    "- 所有测试样本的集合为：测试集（test set），[一般]。\n",
    "- 机器学习出来的模型适用于新样本的能力为：泛化能力（generalization），即从特殊到一般。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假设空间 vs 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:10:49.240414Z",
     "start_time": "2020-03-22T16:10:49.232830Z"
    }
   },
   "source": [
    "**3.1 学习算法**：计算机从数据生成模型的算法\n",
    "\n",
    "**3.2 假设(hypothesis)：**代表我们从假设空间中选取的模型，记为$h_{\\theta}$。对于给定输入$x_1$，模型的预测值为$h_{\\theta}(x_1)$，其中$\\theta$代表模型的参数\n",
    "\n",
    "**3.3 机器学习流程:**数据集经由学习算法，在假设空间中选取合适的假设，并用于接受输入，产生对应的输出\n",
    "- 实际上机器学习就是找输入和输出之间的映射关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt='hypothesis_space' src='./img/hypothesis_space.jpg' width=50% height=50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:21:41.638725Z",
     "start_time": "2020-03-22T16:21:41.635115Z"
    }
   },
   "source": [
    "**3.3 模型的种类：**\n",
    "- 在监督学习中，可以分为`概率模型`和`非概率模型`\n",
    "    - 概率模型：P(Y|X)\n",
    "        - 通常用于分类问题\n",
    "        - 预测\n",
    "    - 非概率模型：f(X)\n",
    "        - 通常用于回归问题\n",
    "        - 预测（不用关心模型的形式，f当作黑箱）与推断（需要知道模型的形式，探究预测变量X怎么影响响应变量Y） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T16:46:23.702372Z",
     "start_time": "2020-03-22T16:46:23.699077Z"
    }
   },
   "source": [
    "**3.4 模型估计:**通过训练数据找输入输出映射关系的方法\n",
    "- 参数估计\n",
    "    - f的形式已知\n",
    "    - 优点：将模型简化为估计一组参数\n",
    "    - 缺点：f的假设形式可能于真正f的形式偏差较大\n",
    "- 非参数估计\n",
    "    - f的形式未知\n",
    "    - 优点：不限定f的形式，在更大范围选择更适合f形状的估计\n",
    "    - 缺点：无法简化模型，需要更多的训练数据。相比于参数估计，复杂度往往更高，当训练数据较少时，容易出现过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5 预测精度和模型解释性的trade-off**\n",
    "- 采用限定结构的模型由较强的解释性\n",
    "    - 复杂度低\n",
    "    - 例如线性回归\n",
    "- 采用复杂度高的模型能拟合复杂形状的f\n",
    "    - 解释性差\n",
    "    - boosting, SVM\n",
    "    \n",
    "<img alt='flexibility_interpretability_trade-off' src='./img/flexibility_interpretability_trade-off.png' width=70% height=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:08:14.513946Z",
     "start_time": "2020-03-22T17:08:14.510430Z"
    }
   },
   "source": [
    "<strong id='variance-bias-trade-off'>[3.6 方差和偏差的trade-off](#trade-off-again)<strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:12:54.377710Z",
     "start_time": "2020-03-22T17:12:54.372227Z"
    }
   },
   "source": [
    "- 复杂度高的模型有高方差，低偏差\n",
    "    - 模型与真实的f较为接近，偏差较少\n",
    "    - 新的训练数据可能会引起模型的剧烈变化\n",
    "- 复杂度低的模型有低方差，高偏差\n",
    "    - 模型与真实的f差别较大，偏差较高\n",
    "    - 新的训练数据可能不会引起模型的剧烈变化\n",
    "- 方差和偏差的变化方向相反\n",
    "    - 泛化误差可以分解为方差、偏差和噪声之和（在泛化误差部分说明）\n",
    "    - 考虑方差、偏差和测试误差之间的关系成为方差和偏差的权衡\n",
    "        - 希望方差和偏差都尽可能的小---一方的增速小于一方的减速\n",
    "        - 例如：线性回归的正则化形式（L1和L2）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T17:40:36.093789Z",
     "start_time": "2020-03-22T17:40:36.091046Z"
    }
   },
   "source": [
    "**4.1 损失函数：**模型一次预测的好坏\n",
    "- 记为L(Y, f(X))，其中（X，Y）代表一条样例（example）\n",
    "- 常用的损失函数\n",
    "\n",
    "0-1损失|平方损失|绝对损失|对数损失\n",
    ":-:|:-:|:-:|:-:\n",
    "$$y = \\begin{cases}1, Y \\neq f(X) \\\\ 0, Y = f(X)\\end{cases}$$|$$(Y-f(X))^2$$|$$|Y - f(X)|$$|$$-log(P|X)$$\n",
    "Bayes判别|线性回归|最小中位数估计|logistic回归\n",
    "\n",
    "- 目标：希望损失越小越好\n",
    "    - 期望风险/泛化误差：$R_{exp} = E_p[L(Y, f(X))] = \\underset{XxY}{\\iint}L(Y, f(X)p(x, y)dxdy$\n",
    "    - 假设X和Y的联合密度函数为p(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 风险函数：**平均意义下模型预测的好坏\n",
    "- $J(\\theta) = \\frac{1}{N} \\displaystyle\\sum_{i = 1}^N L(f_{\\theta}(x_i), y_i)$---(经验风险$R_{emp}$)\n",
    "- 根据大数定律，当N趋于无穷大时，经验风险趋于期望风险\n",
    "    - 当训练集较小时，使用经验风险来估计期望风险并不理想"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T18:43:46.580528Z",
     "start_time": "2020-03-22T18:43:46.574216Z"
    }
   },
   "source": [
    "**4.3 两个基本策略**\n",
    "- 经验风险最小化：$\\underset{f \\in F}{min}\\frac{1}{N} \\displaystyle\\sum_{i = 1}^N L(f_{\\theta}(x_i), y_i)$\n",
    "    - 当训练数据足够大时，能取得很好的效果\n",
    "    - 当训练数据较少时，容易产生过拟合\n",
    "- 结构风险最小化：$R_{srm} = \\underset{f \\in F}{min}\\frac{1}{N} \\displaystyle\\sum_{i = 1}^N L(f_{\\theta}(x_i), y_i) + \\lambda J(f)$\n",
    "    - 实际上时为防止过拟合所采取的正则化手段\n",
    "    - 正则化项$J(f)$是用来描述模型的复杂程度\n",
    "    - $\\lambda$值越大，表明惩罚力度越大，当趋于无穷时，模型则变为最靠近所有训练点的直线；当值为0时，则变为经验风险最小化\n",
    "    - 对于正则化项$J(f)$，lasso的形式为$\\parallel w \\parallel$，ridge的形式为$\\parallel w \\parallel^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法\n",
    "- 模型的具体实现方法\n",
    "- 大多数模型无法求解解析解，只能计算数值解\n",
    "- 90%的机器学习算法都能使用梯度下降算法来解决"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1 过拟合 vs 欠拟合**\n",
    "- 欠拟合：模型学得不好\n",
    "    - 对于神经网络可以增加训练轮数，决策树扩展分支\n",
    "- 过拟合：学得太好，把某些数据特性也学了\n",
    "    - 无法避免，只能缓解\n",
    "    - 结构风险化（正则化的手段）\n",
    "    - 神经网络中采用Dropout和正则化的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:24:02.681201Z",
     "start_time": "2020-03-22T19:24:02.677193Z"
    }
   },
   "source": [
    "**6.2 训练误差 vs 测试误差**\n",
    "\n",
    "**6.2.1 训练端与预测端**\n",
    "- 在模型训练时，对于经验风险最小化和结构风险最小化都使用训练误差来实现优化算法\n",
    "- 而在模型测试时，则使用测试误差来进行评估\n",
    "    - 使用训练误差对模型进行评估会低估模型的误差\n",
    "    - 模型在训练过程中已经“看见”训练集的数据，导致估计结果过于乐观\n",
    "    \n",
    "**6.2.2 变化趋势**\n",
    "- 随着模型复杂度的增加，训练误差逐渐减少直到0\n",
    "    - 极端情况下，模型经过所有的训练点\n",
    "- 随着模型复杂度的增加，测试误差呈现U形，向增加后减少"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T19:29:03.533409Z",
     "start_time": "2020-03-22T19:29:03.523063Z"
    }
   },
   "source": [
    "**6.3 测试误差与泛化误差**\n",
    "\n",
    "- 期望测试误差实际上就是泛化误差：$R_{exp} = E_p[L(Y, f(X))]$\n",
    "    - 实际上无法获得泛化误差，通过平均测试误差来近似---$R_{emp} = \\frac{1}{N'} \\displaystyle \\sum_{i = 1}^{N'} L(Y, f(X))$\n",
    "        - 泛化性能和测试集上的性能（我们通过获得的）未必相同\n",
    "        - 使用不同的测试集，结果会发生变化\n",
    "        - 机器学习算法本身带有随机性，对同一测试集进行多次测试，也可能得到不同的结果\n",
    "- 泛化误差概率上界\n",
    "    - $R_{exp} \\leq R_{emp} + \\varepsilon(N, d, \\delta) = R_{emp} + \\sqrt{\\frac{log(d) + log(\\frac{1}{\\delta})}{2N} }$ \n",
    "    - 有1-$\\delta$的概率满足上式，N是样本数，d代表假设空间的规模。样本数越大，上界趋于0。假设空间规模越大越难学，泛化上界越大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T20:05:26.807311Z",
     "start_time": "2020-03-22T20:05:26.762909Z"
    }
   },
   "source": [
    "- 利用假设检验来揭示测试误差和泛化之间的关系\n",
    "    - 从平均测试误差是泛化误差的近似出发，假设两者之间差别不大，分别记为$\\hat \\varepsilon$和$\\varepsilon$，前者已知，后者未知，假设有m个样本\n",
    "    - 测试集的错误数为$\\hat \\varepsilon * m$，泛化的错误数和测试集错误相同的概率为$P = \\mathrm{C}_{\\hat \\varepsilon * m}^{m}  \\varepsilon^{\\hat \\varepsilon * m} (1 - \\varepsilon)^{m - \\hat \\varepsilon * m}$ \n",
    "    - 对P求导，有当$\\hat \\varepsilon = \\varepsilon$，导数为0，概率取得最大值\n",
    "    - 考虑泛化误差上界，即有$1 - \\delta$的把握使得$\\varepsilon \\leq \\hat \\varepsilon$，则通过$\\sum_{\\hat \\varepsilon * m + 1}^m \\mathrm{C}_{i}^{m}  \\varepsilon^{i} (1 - \\varepsilon)^{m - i} < \\delta$计算出$\\varepsilon$的临界值\n",
    "    - 若$\\hat \\varepsilon$大于临界值，则拒绝假设$\\varepsilon \\leq \\hat \\varepsilon$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T20:56:01.714082Z",
     "start_time": "2020-03-22T20:56:01.710287Z"
    }
   },
   "source": [
    "<strong id = 'trade-off-again'>[6.4 方差和偏差的trade-off再议](#variance-bias-trade-off)</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:09:48.570182Z",
     "start_time": "2020-03-22T21:09:48.564720Z"
    }
   },
   "source": [
    "对于模型$y = f(x) + \\varepsilon$，y为测试集的标记，$f(x)$为真实标记，$\\hat f(x)$为预测值，$\\bar f(x)$为期望预测，等价于$E(\\hat f(x))$，并假设方差均值为0，则泛化误差可以拆分成以下形式\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "E(y - \\hat f(x))^2 & = E(y - \\bar f(x) + \\bar f(x) - \\hat f(x))^2\\\\\n",
    "& = E(y - \\bar f(x))^2 + E(\\bar f(x) - \\hat f(x))^2 \\\\\n",
    "& = E(\\bar f(x) - \\hat f(x))^2 + E(y - f(x) + f(x) - \\hat f(x))^2\\\\\n",
    "& = E(\\bar f(x) - \\hat f(x))^2 + E(f(x) - \\hat f(x))^2 + E(y - f(x))^2\\\\\n",
    "& = Var(\\hat f(x)) + [bias(\\hat f(x))]^2 + var(\\epsilon)\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即泛化误差可以拆分为$\\hat f(x)$的方差---主要描述同样规模的训练集变动所带来的影响，$\\hat f(x)$偏差的平方---主要描述学习算法本身的拟合能力，噪声---即刻画学习任务本身的难度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进一步来说，模型误差可以划分为可约误差和不可约误差。不可约误差是模型本身没有描述的噪声，这决定泛化误差的下限（上式中方差和偏差的平方都为正，即泛化误差的最小值为噪声的平方），可以误差则包括方差和偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt='variance_bias_trade_off' src='./img/variance_bias_trade_off.jpg' width=70% height=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T21:40:15.084250Z",
     "start_time": "2020-03-22T21:40:15.078890Z"
    }
   },
   "source": [
    "**6.5 训练集和测试集的划分方法**\n",
    "\n",
    "**6.5.1 留出法**\n",
    "\n",
    "将数据集划分成互不相容的两部分，一个作为训练集S，一个作为测试集T。\n",
    "- 常见的划分为：大约2/3-4/5的样本用作训练，剩下的用作测试。\n",
    "- 训练/测试集的划分要尽可能保持数据分布的一致性，以避免由于分布的差异引入额外的偏差，常见的做法是采取分层抽样。\n",
    "- 由于划分的随机性，单次的留出法结果往往不够稳定，一般要采用若干次随机划分，重复实验取平均值的做法。\n",
    "\n",
    "**6.5.2 交叉验证法**\n",
    "\n",
    "\n",
    "将数据集D划分为k个大小相同的互斥子集，满足D=D1∪D2∪...∪Dk，Di∩Dj=∅（i≠j），同样地尽可能保持数据分布的一致性，即采用分层抽样的方法获得这些子集。交叉验证法的思想是：每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就有K种训练集/测试集划分的情况，从而可进行k次训练和测试，最终返回k次测试结果的均值。交叉验证法也称“k折交叉验证”，k最常用的取值是10，下图给出了10折交叉验证的示意图。\n",
    "\n",
    "![](https://i.loli.net/2018/10/17/5bc718115d224.png)\n",
    "\n",
    "与留出法类似，将数据集D划分为K个子集的过程具有随机性，因此K折交叉验证通常也要重复p次，称为p次k折交叉验证，常见的是10次10折交叉验证，即进行了100次训练/测试。特殊地当划分的k个子集的每个子集中只有一个样本时，称为“留一法”，显然，留一法的评估结果比较准确，但对计算机的消耗也是巨大的。\n",
    "\n",
    "**6.5.3 自助法**\n",
    "\n",
    "自助法的基本思想是：给定包含m个样本的数据集D，每次随机从D 中挑选一个样本，将其拷贝放入D'，然后再将该样本放回初始数据集D 中，使得该样本在下次采样时仍有可能被采到。重复执行m 次，就可以得到了包含m个样本的数据集D'。可以得知在m次采样中，样本始终不被采到的概率取极限为：\n",
    "$$\\lim_{m \\rightarrow \\infty} (1 - \\frac{1}{m})^m = \\frac{1}{e} \\approx 0.368$$\n",
    "\n",
    "这样，通过自助采样，初始样本集D中大约有36.8%的样本没有出现在D'中，于是可以将D'作为训练集，D-D'作为测试集。自助法在数据集较小，难以有效划分训练集/测试集时很有用，但由于自助法产生的数据集（随机抽样）改变了初始数据集的分布，因此引入了估计偏差。在初始数据集足够时，留出法和交叉验证法更加常用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256.481px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
